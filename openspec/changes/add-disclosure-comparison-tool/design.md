# 開示資料比較・分析ツール 設計書

## Context

企業の開示資料は法定要件を満たす必要があり、複数資料間での記述の整合性が求められる。現状では手作業でのチェックが中心だが、AIを活用することで効率化と品質向上を両立できる。

### Stakeholders
- 経理担当者、IR担当者（主要ユーザー）
- 監査法人、コンサルタント（利用者）
- 経営層（意思決定者）

### Constraints
- PDFファイル形式のみ対応（初期版）
- 日本語の開示資料が主対象
- LLM APIのコスト制約（gpt-5使用）
- レスポンス時間：大規模ファイル（100ページ以上）でも5分以内

## Goals / Non-Goals

### Goals
- 複数PDFファイルの同時アップロードと自動処理
- LLMによる書類種別の自動判定と項目抽出
- 整合性チェックと差分分析の両方に対応
- 直感的なUI/UXで専門知識不要での利用
- 分析結果のエクスポート機能

### Non-Goals
- XBRLやHTML形式への対応（初期版では対象外）
- リアルタイム共同編集機能
- 過去の開示資料データベースの構築（将来的な拡張）
- 多言語対応（初期版は日本語のみ）

## Decisions

### アーキテクチャ

**決定**: フロントエンドとバックエンドの分離アーキテクチャ

- **フロントエンド**: React/Next.js
  - レスポンシブデザイン
  - ドラッグ&ドロップUI
  - インタラクティブなダッシュボード
  
- **バックエンド**: Python/FastAPI
  - PDF解析（PyMuPDF、pdfplumber）
  - LLM統合（OpenAI gpt-5）
  - 非同期処理（Celery + Redis）

**理由**:
- Pythonは豊富なPDF処理ライブラリとAI/MLライブラリが利用可能
- FastAPIは高速で非同期処理に優れる
- Next.jsは優れたUXとSSRによるパフォーマンス最適化が可能

**代替案**:
- フルスタックTypeScript（Node.js + pdf-lib）→ PDF処理ライブラリの成熟度でPythonに劣る
- モノリシック構成 → スケーラビリティと保守性で劣る

### LLM統合戦略

**決定**: OpenAI gpt-5を使用（Vision APIで画像ベースPDF処理）

- 書類種別判定：冒頭20ページの画像をVision APIに送信
- ページマッピング：10ページずつ画像を送信し、直前の結果も文脈として渡す
- テキスト比較：抽出したテキストをテキストAPIで分析

**理由**:
- gpt-5は日本語の理解力が高く、専門的な開示資料の内容を正確に解釈可能
- Vision APIにより画像ベースPDFにも対応
- コンテキストウィンドウが大きく、複数ページの文脈を維持可能

**代替案**:
- Claude 3 → Vision機能があるが、日本語の金融用語理解でgpt-5に劣る可能性
- ローカルLLM（Llama 3等）→ 精度と処理速度で商用APIに劣る

### PDF処理戦略

**決定**: ハイブリッドアプローチ（テキストベース + 画像ベース）

1. まずテキスト抽出を試行（PyMuPDF）
2. テキスト抽出が不十分な場合、画像として処理（pdf2image + Vision API）
3. 表や数値データはpdfplumberで構造化抽出

**理由**:
- テキストベース処理はコストと速度で優位
- 画像ベース処理は精度で優位（スキャンPDF、複雑なレイアウトに対応）
- 用途に応じて自動切り替え

### データフロー

```
[ユーザー] 
  ↓ アップロード
[フロントエンド]
  ↓ POST /api/documents
[バックエンドAPI]
  ↓ 非同期タスク起動
[Celeryワーカー]
  ├→ PDF解析（テキスト/画像）
  ├→ LLM処理（書類判定、マッピング）
  └→ 比較・分析処理
  ↓ 結果保存
[データストア]
  ↓ GET /api/results/{id}
[フロントエンド]
  ↓ 表示
[ユーザー]
```

### 比較ロジック

**数値比較**:
- 表中の数値を抽出し、数値として比較
- 許容閾値：丸め誤差（0.01%）、単位変換（千円/百万円）
- 不一致の場合、原文の該当箇所と差異を記録

**テキスト比較**:
- レベル1：完全一致/部分一致（difflib）
- レベル2：意味の類似度（sentence-transformers: multilingual-e5-large）
- レベル3：トピック抽出（LLM プロンプトエンジニアリング）
- レベル4：トーン分析（ポジティブ/ネガティブ）

## Risks / Trade-offs

### リスク1: LLM APIのコスト超過
**軽減策**:
- ページを10枚ずつバッチ処理
- 画像解像度を最適化（高すぎない設定）
- キャッシュ機構（同じPDFの再アップロード時）

### リスク2: 処理時間の長期化
**軽減策**:
- 非同期処理とプログレスバー表示
- 並列処理（複数ドキュメントを同時処理）
- 段階的な結果表示（項目ごとに結果が出たら順次表示）

### リスク3: LLMの誤判定
**軽減策**:
- ユーザーによる手動修正機能
- 信頼度スコアの表示
- 人間によるレビューを前提とした設計

### トレードオフ: 精度 vs 速度
- 初期版は精度優先（gpt-5使用）
- 将来的に高速化版（gpt-5o-mini）をオプション提供

## Migration Plan

新規プロジェクトのため、マイグレーション不要。

### デプロイ手順
1. バックエンドAPIのデプロイ（FastAPI + Celery + Redis）
2. フロントエンドのデプロイ（Next.js）
3. 環境変数の設定（OpenAI APIキー等）
4. 初期テストの実施

### ロールバック手順
- バックエンド・フロントエンドは独立してロールバック可能
- データストアは初期段階では永続化不要（セッションベース）

## Open Questions

1. **データ保持期間**: アップロードされたPDFや分析結果をどの程度保持するか？
   - ✅ **決定**: 24時間保持後、自動削除（`APP_DOCUMENT_RETENTION_HOURS=24`）

2. **同時処理数の上限**: 1ユーザーが同時にアップロードできるファイル数の上限は？
   - ✅ **決定**: 5ファイルまで（`APP_DOCUMENT_UPLOAD_MAX_FILES=5`）

3. **ファイルサイズ上限**: 1ファイルあたりのサイズ上限は？
   - ✅ **決定**: 50MBまで（`APP_DOCUMENT_UPLOAD_MAX_FILE_SIZE_MB=50`）

4. **認証・認可**: ユーザー認証は必要か？マルチテナント対応は？
   - 🚧 **保留**: 初期版は認証なし、将来的に追加を検討

## 実装状況（セクション2完了時点）

### ✅ 実装完了

**ドキュメント構造化パイプライン（セクション2）:**
- テキスト抽出サービス（PyMuPDF）
- Vision抽出サービス（OpenAI Vision API）
- テーブル抽出サービス（pdfplumber）
- メタデータストア拡張
- Celeryワーカー統合
- 折りたたみ可能なUI表示

**実績データ:**
- 有価証券報告書 234ページ: 5秒で処理完了
- テキスト抽出: 296,499文字
- テーブル抽出: 130個
- Vision APIフォールバック: 未使用（テキスト抽出成功のため）

**技術的な知見:**
- PyMuPDFは高速で、ほとんどのPDFでテキスト抽出に成功
- pdfplumberは表構造を正確に認識（130/130テーブル抽出成功）
- Celery + Redisの組み合わせは安定動作
- UIの折りたたみ機能により、大量データも快適に閲覧可能

### 🚧 次の実装（セクション3以降）

- 比較エンジン
- 結果レポーティング
- E2Eテスト


