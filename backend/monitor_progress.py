"""ã‚»ã‚¯ã‚·ãƒ§ãƒ³æƒ…å ±æŠ½å‡ºã®é€²æ—ç›£è¦–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ"""
import time
import re
from subprocess import run, PIPE

doc_id = "cfd11ff5-298a-4d22-bfb3-34c99247250c"
print(f"ğŸ“Š ã‚»ã‚¯ã‚·ãƒ§ãƒ³æƒ…å ±æŠ½å‡ºã®é€²æ—ã‚’ç›£è¦–ä¸­...")
print(f"ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆID: {doc_id}\n")

last_count = 0
start_time = time.time()

while True:
    # Dockerãƒ­ã‚°ã‹ã‚‰æœ€æ–°ã®é€²æ—ã‚’å–å¾—
    result = run(
        ["docker", "logs", "--tail", "5", "disclosure_celery_worker"],
        capture_output=True,
        text=True
    )
    
    logs = result.stdout + result.stderr
    
    # é€²æ—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢ï¼ˆä¾‹: [5/40]ï¼‰
    matches = re.findall(r'\[(\d+)/(\d+)\]', logs)
    
    if matches:
        current, total = matches[-1]
        current = int(current)
        total = int(total)
        
        if current != last_count:
            elapsed = time.time() - start_time
            progress_pct = (current / total) * 100
            
            # æ¨å®šæ®‹ã‚Šæ™‚é–“ã‚’è¨ˆç®—
            if current > 0:
                avg_time_per_section = elapsed / current
                remaining_sections = total - current
                estimated_remaining = avg_time_per_section * remaining_sections
                
                print(f"â³ é€²æ—: {current}/{total} ({progress_pct:.1f}%) | "
                      f"çµŒé: {elapsed/60:.1f}åˆ† | "
                      f"æ¨å®šæ®‹ã‚Š: {estimated_remaining/60:.1f}åˆ†")
            
            last_count = current
            
            if current >= total:
                print(f"\nâœ… ã‚»ã‚¯ã‚·ãƒ§ãƒ³æƒ…å ±æŠ½å‡ºå®Œäº†ï¼ï¼ˆ{elapsed/60:.1f}åˆ†ï¼‰")
                print("æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: structured_dataã®ä¿å­˜ã‚’å¾…æ©Ÿ...")
                break
    
    # å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ¤œç´¢
    if "Section content extraction completed" in logs or "structured" in logs:
        print("\nâœ… å‡¦ç†å®Œäº†ã®å¯èƒ½æ€§ã‚ã‚Šï¼")
        break
    
    time.sleep(5)

print("\nå‡¦ç†å®Œäº†ã‚’ç¢ºèªä¸­...")
time.sleep(5)

# æœ€çµ‚ç¢ºèª
import json
from pathlib import Path

meta_path = Path(f"storage/metadata/{doc_id}.json")
if meta_path.exists():
    print(f"âœ… ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚Œã¾ã—ãŸï¼")
    with open(meta_path, 'r', encoding='utf-8') as f:
        meta = json.load(f)
        
    sections = meta.get('structured_data', {}).get('sections', {})
    sections_with_content = sum(
        1 for s in sections.values() if 'extracted_content' in s
    )
    
    print(f"ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ•°: {len(sections)}")
    print(f"extracted_content ã‚ã‚Š: {sections_with_content}/{len(sections)}")
else:
    print("âš ï¸ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒã¾ã ä½œæˆã•ã‚Œã¦ã„ã¾ã›ã‚“")

